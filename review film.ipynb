{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMjv0RBnaDLyNtecnxIpCIb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sh3UoUc9Cm01","executionInfo":{"status":"ok","timestamp":1754463158273,"user_tz":-420,"elapsed":121848,"user":{"displayName":"Rangga Arya Savero","userId":"16422288886654807395"}},"outputId":"28bd2c61-d7e3-4b2a-d4e6-a500c151d356","collapsed":true},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["data awal (5 barisan pertama):\n","                                              review sentiment\n","0  One of the other reviewers has mentioned that ...  positive\n","1  A wonderful little production. <br /><br />The...  positive\n","2  I thought this was a wonderful way to spend ti...  positive\n","3  Basically there's a family where a little boy ...  negative\n","4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n","--------------------------------------------------\n","data setelah pembersihan:\n","                                              review  \\\n","0  One of the other reviewers has mentioned that ...   \n","1  A wonderful little production. <br /><br />The...   \n","2  I thought this was a wonderful way to spend ti...   \n","3  Basically there's a family where a little boy ...   \n","4  Petter Mattei's \"Love in the Time of Money\" is...   \n","\n","                                        clean_review  \n","0  one review mention watch oz episod youll hook ...  \n","1  wonder littl product film techniqu unassum old...  \n","2  thought wonder way spend time hot summer weeke...  \n","3  basic there famili littl boy jake think there ...  \n","4  petter mattei love time money visual stun film...  \n","--------------------------------------------------\n","informasi dataframe setelah dibersihkan\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 50000 entries, 0 to 49999\n","Data columns (total 3 columns):\n"," #   Column        Non-Null Count  Dtype \n","---  ------        --------------  ----- \n"," 0   review        50000 non-null  object\n"," 1   sentiment     50000 non-null  int64 \n"," 2   clean_review  50000 non-null  object\n","dtypes: int64(1), object(2)\n","memory usage: 1.1+ MB\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","\n","# unduh stop words (hanya perlu dijalankan sekali)\n","nltk.download('stopwords')\n","\n","# memuat dataset\n","df = pd.read_csv('IMDB Dataset.csv')\n","\n","print(\"data awal (5 barisan pertama):\")\n","print(df.head())\n","print(\"-\" * 50)\n","\n","#3. pembersihan dan pra-pemrosesan data\n","#konversi kolom sentiment\n","df['sentiment'] = df['sentiment'].map({'positive' : 1, 'negative' : 0})\n","\n","#inisialisasi stop words dan stemmer\n","stop_words = set(stopwords.words('english'))\n","stemmer = PorterStemmer()\n","\n","#fungsi untuk membersihkan data\n","def clean_data(text):\n","  #menghapus tag HTML\n","  text = re.sub(r'<.*?>', '', text)\n","\n","  #mengubah teks menjadi huruf kecil\n","  text = text.lower()\n","\n","  #menghapus tanda baca dan karakter non-alfabet\n","  text = re.sub(r'[^a-z\\s]', '', text) # Corrected regex\n","\n","  #tokenisasi\n","  tokens = text.split()\n","\n","  #menghapus stop words\n","  tokens = [word for word in tokens if word not in stop_words]\n","\n","  #steming\n","  tokens = [stemmer.stem(word) for word in tokens]\n","\n","  #menggabungkan kembali token menjadi string\n","  return ' '. join(tokens)\n","\n","#menerapkan fungsi pembersihan ke kolom 'review'\n","df['clean_review'] = df['review'].apply(clean_data) # Added apply function\n","\n","print(\"data setelah pembersihan:\")\n","#tampilkan kolom review asli dan clean_review yang baru\n","print(df[['review', 'clean_review']].head())\n","\n","#tampilkan ringkasan data yang sudah bersih\n","print(\"-\" * 50)\n","print(\"informasi dataframe setelah dibersihkan\")\n","df.info()"]},{"cell_type":"code","source":["#import library untuk model\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","#vektorisasi teks\n","#inisialisasi TfidfVectorizer\n","tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n","\n","#terapkan TF-IDF ke kolom clean review\n","#'x' akan berisi representasi numerik dari teks\n","X = tfidf_vectorizer.fit_transform(df['clean_review'])\n","y = df['sentiment']\n","\n","#membagi data menjadi data lath dan uji\n","#bagi data dengan perbandingan 80% dan uji 20%\n","x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","print(\"jumlah data latih : \", x_train.shape[0])\n","print(\"jumlah data uji : \", x_test.shape[0])\n","print(\"-\" * 50)\n","\n","#melatih model logistic regression\n","#inisialisasi model\n","model = LogisticRegression()\n","\n","#latih model menggunakan data latih\n","model.fit(x_train, y_train)\n","\n","print(\"model berhasil dilatih\")\n","print(\"-\" * 50)\n","\n","#evaluasi model\n","#lakukan prediksi pada data uji\n","y_pred = model.predict(x_test)\n","\n","#hitung akurasi model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"akurasi model: {accuracy:.4f}\")\n","\n","#tampilkan laporan klasifikasi lengkap\n","print(\"laporan klasifikasi:\")\n","print(classification_report(y_test, y_pred))"],"metadata":{"id":"e1lBfCzTWbRN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754463354940,"user_tz":-420,"elapsed":7486,"user":{"displayName":"Rangga Arya Savero","userId":"16422288886654807395"}},"outputId":"b9ee0be4-f6be-459c-d7ec-37ae48946982"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["jumlah data latih :  40000\n","jumlah data uji :  10000\n","--------------------------------------------------\n","model berhasil dilatih\n","--------------------------------------------------\n","akurasi model: 0.8838\n","laporan klasifikasi:\n","              precision    recall  f1-score   support\n","\n","           0       0.89      0.87      0.88      4961\n","           1       0.87      0.90      0.89      5039\n","\n","    accuracy                           0.88     10000\n","   macro avg       0.88      0.88      0.88     10000\n","weighted avg       0.88      0.88      0.88     10000\n","\n"]}]},{"cell_type":"markdown","source":["Tahap 1: Memuat dan Membersihkan Data\n"],"metadata":{"id":"VkGRPodaU7Y3"}},{"cell_type":"markdown","source":["Tahap 2: Pemodelan dan Evaluasi"],"metadata":{"id":"xQ-tfj7MVACn"}},{"cell_type":"markdown","source":["Proyek Data Science: Analisis Sentimen Ulasan Film"],"metadata":{"id":"B-E0REdRUwNh"}}]}